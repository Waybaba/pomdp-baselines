description: AMLT

target:
  service: singularity
  name: msrresrchvc    # more GPUs 

environment:
  image: waybaba/rl:rnn_strong
  username: waybaba
  setup:
    - echo "setup start..."
    - export UPRJDIR=/mnt/default/
    - export UDATADIR=/mnt/storage/data
    - export UOUTDIR=/mnt/storage/output
    - mkdir -p /mnt/storage/output /mnt/storage/data
    - echo "setup finished!"


code:
  local_dir: $CONFIG_DIR/../../

storage:
  input:
    storage_account_name: resrchvc4data
    container_name: v-wangwei1
    mount_dir: /mnt/storage
    local_dir: /home/v-wangwei1/storage

# search:
#   job_template:
#     name: delay_{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=tianshou.policy.SACPolicy
#       env.delay={env_delay}
#       seed={seed}
#       tags=["delay_amlt_test_2"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000,100000,10000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]


# search:
#   job_template:
#     name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=agent.sac.AsyncACSACPolicy
#       env.delay={env_delay}
#       net={net}
#       net@net_c1={net}
#       seed={seed}
#       tags=["delay_amlt_rnn_and_normal"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000,100000,10000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]
#     - name: net
#       values: [default,rnn]

# # mine_with_params_as_donqi
# search:
#   job_template:
#     name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=agent.sac.AsyncACSACPolicy
#       env.delay={env_delay}
#       net={net}
#       net@net_c1={net}
#       seed={seed}
#       tags=["mine_with_params_as_donqi"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]
#     - name: net
#       values: [default]


# # mine_with_params_as_donqi_plus_net
# search:
#   job_template:
#     name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=agent.sac.AsyncACSACPolicy
#       env.delay={env_delay}
#       net={net}
#       net@net_c1={net}
#       seed={seed}
#       tags=["mine_with_params_as_donqi_plus_net"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]
#     - name: net
#       values: [default]


# search:
#   job_template:
#     name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=agent.sac.AsyncACSACPolicy
#       env.delay={env_delay}
#       net={net}
#       net@net_c1={net}
#       seed={seed}
#       tags=["mine_with_params_as_donqi_plus_net_trainable_alpha_lr_change"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]
#     - name: net
#       values: [default]

# # mine_with_params_as_donqi_plus_net_trainable_alpha_lr_change_reg_7
# search:
#   job_template:
#     name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       policy.critic_use_oracle_obs={critic_use_oracle_obs}
#       collector.train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=agent.sac.AsyncACSACPolicy
#       env.delay={env_delay}
#       env.name={env_name}
#       net={net}
#       net@net_c1={net}
#       seed={seed}
#       tags=["START_complex"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]
#     - name: critic_use_oracle_obs
#       values: [true]
#     - name: net
#       values: [default]
#     - name: env_name
#       # values: [HalfCheetah-v4]
#       values: [Ant-v4,Hopper-v4,Walker2d-v4]

search:
  job_template:
    name: RL_RNN_{experiment_name:s}_{auto:5s}
    # sku: 24G1-P40
    sku: G1
    # sku: G1-V100
    command:
    # - python policies/main.py --cfg configs/delayed/rnn.yml --seed {seed} --algo sac --{ifdebug} --env Delayed-v0 --sub_env_name {env_name} --delay_steps {delay_step} --cuda 0 --tags [{tags}]
    - python policies/main.py --cfg configs/delayed/rnn.yml --seed {seed_base}0 --algo {algo} --{ifdebug} --{ifcatact} --env Delayed-v0 --sub_env_name {env_name} --delay_steps {delay_step} --cuda 0 --tags [{tags}] &
      python policies/main.py --cfg configs/delayed/rnn.yml --seed {seed_base}1 --algo {algo} --{ifdebug} --{ifcatact} --env Delayed-v0 --sub_env_name {env_name} --delay_steps {delay_step} --cuda 0 --tags [{tags}] &
      python policies/main.py --cfg configs/delayed/rnn.yml --seed {seed_base}2 --algo {algo} --{ifdebug} --{ifcatact} --env Delayed-v0 --sub_env_name {env_name} --delay_steps {delay_step} --cuda 0 --tags [{tags}] &
      python policies/main.py --cfg configs/delayed/rnn.yml --seed {seed_base}3 --algo {algo} --{ifdebug} --{ifcatact} --env Delayed-v0 --sub_env_name {env_name} --delay_steps {delay_step} --cuda 0 --tags [{tags}] &
      python policies/main.py --cfg configs/delayed/rnn.yml --seed {seed_base}4 --algo {algo} --{ifdebug} --{ifcatact} --env Delayed-v0 --sub_env_name {env_name} --delay_steps {delay_step} --cuda 0 --tags [{tags}]
     
  type: grid
  max_trials: 10000
  params:
    - name: ifdebug
      values: [nodebug]
    - name: ifcatact
      values: [noenv_cat_action]
    - name: delay_step
      values: [0,1,2,4,8,12]
    - name: algo
      values: [td3,sac]
    - name: env_name
      # values: [HalfCheetah-v4]
      # values: [HopperBulletEnv-v0,HalfCheetahBulletEnv-v0,Walker2DBulletEnv-v0,AntBulletEnv-v0]
      values: [HalfCheetah-v4,Hopper-v4,Ant-v4,Walker2d-v4,Swimmer-v4, Reacher-v4]
    - name: seed_base
      values: [5]
    - name: tags
      values: ["final_sweep_rnnStrong_3"]